{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RL_TS2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Case Study:</b> - In this Reinforcement Learning framework for trading strategy, the algorithm takes an action (buy, sell or hold) depending upon the current state of the stock price. The algorithm is trained using Deep Q-Learning framework, to help us predict\n",
    "the best action, based on the current stock prices. \n",
    "\n",
    "The key components of the RL based framework are :\n",
    "* Agent: in this conext it is the trading agent.\n",
    "* Action: It could range betwwwn \"Buy, sell or hold\".\n",
    "* Reward function: This is a tricky one - in our case it is defined as \"Realized profit and loss (PnL)\" \n",
    "for this case study. The reward typically depends upon the action:\n",
    "    * Sell: Realized profit and loss (sell price - bought price)\n",
    "    * Buy: No reward\n",
    "    * Hold: No Reward \n",
    "\n",
    "* State: Differences of past stock prices for a given time window is used as the state.\n",
    "\n",
    "The data used for this case study will be the S&P500 data for the Period of Jan'2010 to Feb'2021. The link to the data is : https://ca.finance.yahoo.com/quote/%255EGSPC/history?p=%255EGSPC).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">Download/import the relevant packages</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv, set_option\n",
    "from pandas.plotting import scatter_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "import math\n",
    "from numpy.random import choice\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Import Model Packages for reinforcement learning\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from collections import namedtuple, deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diable the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">Load the Dataset</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/shovonsengupta/Desktop/All/EC-Council Course/AI for Finance - Videos/Section 8 Overview on Applications of Reinforcement Learning for Finance /Codes\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sp500 = read_csv('/Users/shovonsengupta/Desktop/All/EC-Council Course/AI for Finance - Videos/Section 8 Overview on Applications of Reinforcement Learning for Finance /data/SP500_base_data_yahoo_2021.csv',index_col=0)\n",
    "df_sp500 = read_csv('/Users/shovonsengupta/Desktop/All/EC-Council Course/AI for Finance - Videos/Section 8 Overview on Applications of Reinforcement Learning for Finance /data/SP500.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1116.560059</td>\n",
       "      <td>1133.869995</td>\n",
       "      <td>1116.560059</td>\n",
       "      <td>1132.989990</td>\n",
       "      <td>1132.989990</td>\n",
       "      <td>3991400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1132.660034</td>\n",
       "      <td>1136.630005</td>\n",
       "      <td>1129.660034</td>\n",
       "      <td>1136.520020</td>\n",
       "      <td>1136.520020</td>\n",
       "      <td>2491020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-06</th>\n",
       "      <td>1135.709961</td>\n",
       "      <td>1139.189941</td>\n",
       "      <td>1133.949951</td>\n",
       "      <td>1137.140015</td>\n",
       "      <td>1137.140015</td>\n",
       "      <td>4972660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-07</th>\n",
       "      <td>1136.270020</td>\n",
       "      <td>1142.459961</td>\n",
       "      <td>1131.319946</td>\n",
       "      <td>1141.689941</td>\n",
       "      <td>1141.689941</td>\n",
       "      <td>5270680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-08</th>\n",
       "      <td>1140.520020</td>\n",
       "      <td>1145.390015</td>\n",
       "      <td>1136.219971</td>\n",
       "      <td>1144.979980</td>\n",
       "      <td>1144.979980</td>\n",
       "      <td>4389590000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close  \\\n",
       "Date                                                                          \n",
       "2010-01-04  1116.560059  1133.869995  1116.560059  1132.989990  1132.989990   \n",
       "2010-01-05  1132.660034  1136.630005  1129.660034  1136.520020  1136.520020   \n",
       "2010-01-06  1135.709961  1139.189941  1133.949951  1137.140015  1137.140015   \n",
       "2010-01-07  1136.270020  1142.459961  1131.319946  1141.689941  1141.689941   \n",
       "2010-01-08  1140.520020  1145.390015  1136.219971  1144.979980  1144.979980   \n",
       "\n",
       "                Volume  \n",
       "Date                    \n",
       "2010-01-04  3991400000  \n",
       "2010-01-05  2491020000  \n",
       "2010-01-06  4972660000  \n",
       "2010-01-07  5270680000  \n",
       "2010-01-08  4389590000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2516, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sp500.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">Exploratory Data Analysis</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>3225.449951</td>\n",
       "      <td>3226.429932</td>\n",
       "      <td>3220.510010</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>3223.379883</td>\n",
       "      <td>1296540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3240.080078</td>\n",
       "      <td>3227.199951</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>3239.909912</td>\n",
       "      <td>2160680000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>3247.229980</td>\n",
       "      <td>3247.929932</td>\n",
       "      <td>3234.370117</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>3240.020020</td>\n",
       "      <td>2428670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>3240.090088</td>\n",
       "      <td>3240.919922</td>\n",
       "      <td>3216.570068</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>3221.290039</td>\n",
       "      <td>3013290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-31</th>\n",
       "      <td>3215.179932</td>\n",
       "      <td>3231.719971</td>\n",
       "      <td>3212.030029</td>\n",
       "      <td>3230.780029</td>\n",
       "      <td>3230.780029</td>\n",
       "      <td>2893810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open         High          Low        Close    Adj Close      Volume\n",
       "Date                                                                                   \n",
       "2019-12-24  3225.449951  3226.429932  3220.510010  3223.379883  3223.379883  1296540000\n",
       "2019-12-26  3227.199951  3240.080078  3227.199951  3239.909912  3239.909912  2160680000\n",
       "2019-12-27  3247.229980  3247.929932  3234.370117  3240.020020  3240.020020  2428670000\n",
       "2019-12-30  3240.090088  3240.919922  3216.570068  3221.290039  3221.290039  3013290000\n",
       "2019-12-31  3215.179932  3231.719971  3212.030029  3230.780029  3230.780029  2893810000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# peek at data\n",
    "set_option('display.width', 100)\n",
    "df_sp500.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has total 2807 rows and six columns which contain the open, high, low, close and adjusted close price along with the total volume. The adjusted close is the closing price adjusted for the split and dividends. For the purpose of this case study, we will be focusing on the closing price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2516.000</td>\n",
       "      <td>2516.000</td>\n",
       "      <td>2516.000</td>\n",
       "      <td>2516.000</td>\n",
       "      <td>2516.000</td>\n",
       "      <td>2.516e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1962.148</td>\n",
       "      <td>1971.347</td>\n",
       "      <td>1952.200</td>\n",
       "      <td>1962.609</td>\n",
       "      <td>1962.609</td>\n",
       "      <td>3.715e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>589.031</td>\n",
       "      <td>590.191</td>\n",
       "      <td>587.624</td>\n",
       "      <td>588.910</td>\n",
       "      <td>588.910</td>\n",
       "      <td>8.134e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1027.650</td>\n",
       "      <td>1032.950</td>\n",
       "      <td>1010.910</td>\n",
       "      <td>1022.580</td>\n",
       "      <td>1022.580</td>\n",
       "      <td>1.025e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1381.643</td>\n",
       "      <td>1390.700</td>\n",
       "      <td>1372.800</td>\n",
       "      <td>1384.405</td>\n",
       "      <td>1384.405</td>\n",
       "      <td>3.238e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1985.320</td>\n",
       "      <td>1993.085</td>\n",
       "      <td>1975.660</td>\n",
       "      <td>1986.480</td>\n",
       "      <td>1986.480</td>\n",
       "      <td>3.588e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2434.180</td>\n",
       "      <td>2441.523</td>\n",
       "      <td>2427.960</td>\n",
       "      <td>2433.968</td>\n",
       "      <td>2433.968</td>\n",
       "      <td>4.077e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3247.230</td>\n",
       "      <td>3247.930</td>\n",
       "      <td>3234.370</td>\n",
       "      <td>3240.020</td>\n",
       "      <td>3240.020</td>\n",
       "      <td>1.062e+10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Open      High       Low     Close  Adj Close     Volume\n",
       "count  2516.000  2516.000  2516.000  2516.000   2516.000  2.516e+03\n",
       "mean   1962.148  1971.347  1952.200  1962.609   1962.609  3.715e+09\n",
       "std     589.031   590.191   587.624   588.910    588.910  8.134e+08\n",
       "min    1027.650  1032.950  1010.910  1022.580   1022.580  1.025e+09\n",
       "25%    1381.643  1390.700  1372.800  1384.405   1384.405  3.238e+09\n",
       "50%    1985.320  1993.085  1975.660  1986.480   1986.480  3.588e+09\n",
       "75%    2434.180  2441.523  2427.960  2433.968   2433.968  4.077e+09\n",
       "max    3247.230  3247.930  3234.370  3240.020   3240.020  1.062e+10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary Stats\n",
    "# describe data\n",
    "set_option('precision', 3)\n",
    "df_sp500.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEGCAYAAACQO2mwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2z0lEQVR4nO3deXxU1fn48c+TPYEQAiTsGED2VQmLOwoiiErdl4pWrVR/2mq/thb3FYtL3W2rdbfWpdXWBRREXFBklX0PECAsIRAgCdlnzu+Pe2cyk5lJJmGSmSTP+/Xixb3nnnvnXGaYZ849mxhjUEoppfyJCncBlFJKRS4NEkoppQLSIKGUUiogDRJKKaUC0iChlFIqoJhwF6AmHTp0MBkZGeEuhlJKNSnLly8/YIxJC8W1IjpIZGRksGzZsnAXQymlmhQR2RGqa+njJqWUUgFpkFBKKRWQBgmllFIBaZBQSikVkAYJpZRSAWmQUEopFZAGCaWUUgFpkFBKqQjzwdKd7DxYHO5iABE+mE4ppVqa3IJS/vTRGgCyZ04Oc2m0JqGUUhHl5x2Hwl0ELxoklFIqguw9UgrA05cNC3NJLBoklFIqgizbkQ/AhSd0DXNJLBoklFIqgsxes49WcdGISLiLAmiQUEqpiGGMAeDM/ulhLkkVDRJKKRUhcg6VANCvY3KYS1JFg4RSSkWArP2FXP7yTwD0Tm8d5tJU0SChlFIR4K6P17DH7tmUlhwf5tJU0SChlFIRoMJh3NupSXFhLIk3DRJKKRVm6/cUsHLXYfd+77RW4StMNRoklFIqzJbv9B5lHSndX0GDhFJKhd2PWw64t2OiIidAgAYJpZQKqwqHky/X7XPv33Lm8WEsjS+dBVYppcLojR+3AzBpcCf+dvWIMJfGl9YklFIqjDbnFgHw6C8Gh7kk/mmQUEqpMCqpcADQvnXkjI3wpEFCKaXCxBjDrNV7w12MGtUaJEQkQUSWiMgqEVknIg/Z6T1FZLGIZInIByISZ6fH2/tZ9vEMj2vdZadvEpFzGuyulFIqQqzcdZjcglK/xw4VVzRyaeoumJpEGXCWMWYYMByYKCJjgMeBZ4wxxwOHgBvs/DcAh+z0Z+x8iMhA4ApgEDAR+KuIRIfwXpRSKqJ8u2k/v3jpR0Y/9rXf4weKygB47orhjViquqk1SBhLkb0ba/8xwFnAf+z0t4Bf2NtT7H3s4+PEGhkyBXjfGFNmjNkOZAGjQnETSikVafYcLuFXbyz1SR/92Dwyps+iuLySNxdmA3Bc+8gZYV1dUG0SIhItIiuB/cBXwFbgsDGm0s6SA7iWUeoK7AKwjx8B2num+zlHKaWalfs/WeuT5nQacgus2sPCrIP8a/FOAHpF0DQc1QUVJIwxDmPMcKAb1q///g1VIBGZJiLLRGRZXl5eQ72MUko1qHkb9vuk5ReXu7dv+udy93abhNhGKVN91Kl3kzHmMPANcBLQVkRcg/G6Abvt7d1AdwD7eApw0DPdzzmer/GKMSbTGJOZlpZWl+IppVTEMsYwx2NkdaXTmvX18szugU6JCMH0bkoTkbb2diJwNrABK1hcYme7FvjE3v7U3sc+Pt9Ya/J9Clxh937qCfQBloToPpRSKmKUlFtjH7qlJjKmVzsAyiqdFJVW+uQdbR+PVMFMy9EZeMvuiRQFfGiM+VxE1gPvi8ijwArgNTv/a8A7IpIF5GP1aMIYs05EPgTWA5XALcYYR2hvRymlGpcxhu+3HGBkRipJcdZX6uAH5wDWPEwVDieLtuVTVFZJYWklUQLpyQnss7vFjuvfMWxlD0atQcIYsxo4wU/6Nvz0TjLGlAKXBrjWDGBG3YuplFKR6am5m3jpm61ECWz782SMMTjsR0mpSbEUlVm/hRdsyaOorJLW8THcNr4Pd328BoDWCZE9hZ6OuFZKtUj/XZFD//u+4NUF247pOi99sxUAOy5wtLzqAUmH1vG0jreGg/3+g1W8uTCbgtJKnKZqFbroCJsavDoNEkqpFqWk3MG89bk8+eUmSiucPDprg7sNIRQKSqpGUaclxxMX4/s163Qan7RIFdn1HKWUCrGHPlvH+0t3eaUdLiknMS6xztd67Yft7u2EWCsYFJRWBYn05ASyDxb7nOdoQkFCaxJKqRZlZ77vl/aRkrrPoVRa4eCRz9e797u2tYKMa+rvd389msS4aJ+V5oZ3b+vu/toUaJBQSrUox7VP8knbnne0ztdZtO2ge/v8YV3YmncUYwy/e28FAO1axQEQVW296qtG96BTSkKdXy9cNEgopZqELbmF3PmfVVQ6nMd0nbzCqlHPi+8eB8CGvQV1vs6GvYUAtG8Vx2er9gDQ867Z7uP9OyUDUFTmPTZi35FSJg/pzBvXjWTbY+fW+XUbmwYJpVST8Nv3VvDhshy27C+qPbMfpRUO3vhxO/M25AJw0xm96dgmgbjoKCrq+PinwuF0X+fH6Wfxy9E9vI7fcXZfxK5BVFQLakO7pSAinNkvnagI79kEGiSUUk2E67FNfRp9S8od3P/JWh76zGpDSE2KZfokawq66Cipc+3kpneWs3zHIQZ2bkNCbDTjB3oPiGubVDUXU/UgMTIjskdYV6dBQinVJKy3HwmVVda9u+qM2ev5cFmOe//TW091b8dES50bkr/eaE3eF6htoU1iVZDo2cF7htfE2Ka1jI52gVVKNSl7Dpcy4ri6nePqceSS3qZqPemYKKHSUb/eRklx1hd+9XEWKR5BYmi3tsy5/XTmb9zPjaf1bBKPmDxpTUIp1aTMXlO3NaGNMSzZnu+VFh9T9Ws+OiqK/OJy8grL+NRugK5JcXlVQ7RrWdLiakEiudrU3/06JXPz2N7ERDe9r1ytSSilIl6hxwA1V9fSYOUcKvHaf/ziIV77B4rKmLV6L2tyjrAzv5ihXVPI6OB/EaDSCgfnv/CDe39p9iGgqieTi2tgXXPQfO5EKdVsef7Cd8175HSaGqe3KK90Yozhwr8udKc9eclQLh/Zw29+1yC7PYdLWLDF/4Jnwx6ay1aPMRXPX2nNfTq4awprHpzgTvesqTR1WpNQSkW895bsdG9XOgw/bDnA1NcXM2FgR16emumTv7C0giEPzmVQlzYcKLKWC9386CS/8yhV9/sPV5JbUMa3fxjrVaMoLK2grLKqp9KLV53AeUO7uPc9HzE1p5qEBgmlVMRbu7tqsFuFw8nVry0GYM66XL/5X/7Omtl13Z6q84IJEIB7Deryal1XV+467LV/9sDA60A0p5pE8wl3Sqlm64Jh1i/2nh1aeU3FHcj2A97TbLjmVaqLuGqNzNVXlaspEDSnmkTzuROlVLPlapOIjhKO+pnmorr4arWG84d18clTG4fxbu+4+d2fgz5XaxJKKdVI8gqtxz9d2yYSEyXufZct+wu99tfkHOHjFbvp17Gqx5HnCOhgeY7s9nxN19gIfy4Z0Q2A2OimNRaiJhoklFIRbX+hVVO477yBREeJz9xNQtUX8ovzt3D+i1YX1S5tq0ZDJwTZHuHJc4Ddqz9UrV730/Rx/HTXWX7Pefzioax96Bz3vE3NgQYJpVREO3TUGiPRrlWcz9oMAN9s2k+lw0l5pZOn5m72SK/qxropt9DnPJd/3jDab7rnEqOej7hSkmLpnOK/jSM6Smgd37z6AzWvu1FKNTv5xdbU3u1axfpdD3pZdj6/fHUxi6uNqvZ03Sk9Ax47tU8Hv+me8zkVlFhBolUNj5qaK61JKKUi1q78Yt5emA1AalIcP+887HU8KS6awV1T3AFixHGp7mOTBneid5o1zqFvR+8R0cE4WFTVDuGqScy+7bQ6X6ep05qEUipinf3Md5RWWOMVPCfNc0lOiPGaivtgURkZ7ZPIPljM/xt7PH07tcbUYe6+rm0T2X3YmsbDc0nTkgoHIzNSOa69/+k6mjOtSSilIlaruKrfsf4mx4uLiaLCo4E5+2AxIzPakT1zMkO6pRAfE01CHabm9hxw5wo+c9ftY+HWg3W6TnOiQUIpFZEKSys4eNRqj/jXr70bly86sStbZkxiV34J/12x2+tYTV1Ua+PZ5OEKPtPeWQ7Agi0H6n3dpkyDhFIq4hhjuOHNZe79k4/3blxOiosmNsC02yN71n/lN9ckfwD3/m9tva/TnGiQUEpFnJIKB0uyrcZoz1rESb3aA5BQw4jmeqxuyr2TBwB4PbpSFg0SSqmIs+Ng1S96z5rBGFeQqKF9oK2fBu7aXH9KT96fNoYFd57plW48Wr3n33FGna/bHGjvJqVUxNl7xOph9KuTM7weK5Xa61sn+ml3WPfQOSzfcYjTAox7qElUlLgD0IaHJ/LK99t4Zt5mKhyGbqmJDO/ell5pretzK02e1iSUUhHnfyusCf2uHuO9QJBrLenqE/iB1U5xet+0Y54SIzEumsQ46/rlDic5h0ro0Dq+lrOaL61JKKUihtNpOOOpb9iVb9UkurZN8jpeZtck/D1uCuV8Sa7ay7+X7QK8G7RbGq1JKKUigsNpuPq1xe4AAb6PlVwNy4l2kHBNkzGsW0pIy+IaL/HhshzAu2tsS6M1CaVURHhizkYWbj3o3k9P9n3Ec+fEfkSLMHloZwDWPnQOz329hcsyu4e0LK4Fh7q2TWTD3gKeuGRYSK/flGiQUEqF3dGySveSoy4zLhziky89OYHHLxnq3hcRbh/fN+TlcdUk8gpL6ZaaSLtWcSF/jaZCg4RSKuwGPTDHvf3W9aMY2LkNaX5qEo3FVZPYuK+wXpMDNicaJJRSEWPVAxP8TuTX2FrZa0KUVTqPaZqP5qDWhmsR6S4i34jIehFZJyK32ekPishuEVlp/znX45y7RCRLRDaJyDke6RPttCwRmd4wt6SUakry7fmZ7ji7b0QECIAe7ap6VcXVY1W75iSYmkQlcIcx5mcRSQaWi8hX9rFnjDFPeWYWkYHAFcAgoAswT0RcDw1fAs4GcoClIvKpMWZ9KG5EKdU0zV6zF4ATeqTWkrPxxMf6zgbbUtUaJIwxe4G99nahiGwAutZwyhTgfWNMGbBdRLKAUfaxLGPMNgARed/Oq0FCqRbq6w257on0+naMnBHN8R5zQy3aFnjFu5agTvUoEckATgAW20m3ishqEXldRFw/A7oCuzxOy7HTAqVXf41pIrJMRJbl5eVVP6yUakZueKtqptdwNlRX529Ed0sV9L+EiLQGPgJuN8YUAH8DegPDsWoafwlFgYwxrxhjMo0xmWlpaaG4pFIqAjidhncX7yBj+ixenL+FA/byoOnJ8Sy488yQjpg+VhokqgTVu0lEYrECxLvGmI8BjDG5Hsf/AXxu7+4GPEe2dLPTqCFdKdXMfbluH/f813q09NTczTw1dzMA4wZ0pHu7pJpObXT+VsFrqYLp3STAa8AGY8zTHumdPbJdCLhW6PgUuEJE4kWkJ9AHWAIsBfqISE8RicNq3P40NLehlIpUa3cf4WBRGZ+v3uP3+Nb9RY1cIlUXwdQkTgGmAmtEZKWddjdwpYgMBwyQDfwGwBizTkQ+xGqQrgRuMcY4AETkVmAOEA28boxZF7I7UUpFnNIKB+e98AMAPTu0oktKAultEli567A7z9+njghT6YKjXWBrYYz5AfD3sHB2DefMAGb4SZ9d03lKqeZj7e4j7gABsP3AUa4/pSclFZXuIHHz2N4RP+XF7N+dFu4ihFXLDpFKqQazKuewT1pCbBR/PKe/e/8PE/o1Yonq5/j0yOmaGw4aJJRSDcLVSP2Yx0R9p/VJo12rOP55w2hemTqC6JY8B3cToXM3KaXqbcfBo3RPTSLK48t+1a7DTHnpR/f+laO6U1BawcwvNpKZYQ2nOrUeS4yq8NCahFKqXnYeLOaMJ7/ltg9WUlBaAVjtEJ4B4qlLhyEi3HRGb7JnTvZar1o1DfqOKaXq5VCxNTHfZ6v2cNZT3wHw7LzNXnkiaaoNVT8aJJRS9fLC/C3u7QNFZTw2ewMpid49lbqnRtYgOVV32iahlKqXeRv2e+2/8v02nzxtkyJj6m9VfxoklFJ1ti3PGiV9Vv90Kp2G7zd7T8b5/rQxrN19JKLmY6qrxNhoSioc4S5G2GmQUErV2bo9BQBcPaYH8THRPkFiTK/2jOnVPhxFC5ml947H4TDhLkbYaZuEUqrO9h4pAWDEce045fgOZM2YxPRJ1iC55jJCuXV8DCn6uExrEkqpuss5VEKbhBj3cqMx0VH85vReXHRiV9KTE8JcOhVKWpNQStXJO4t28PZPO3wWCRIRDRDNkAYJpVTQCkoruM9ebjT7YHGYS6Magz5uUkrVyOk0HCouJ7egjHOfX+BO//vVkT3FtwoNDRJKqRo9O28zz8/P8krr2Caecf3Tw1Qi1Zj0cZNSqkbVAwTAZ7891WtSP9V8aZBQStWod1orr/3smZO1gboF0SChlKpRm8RYTrIHxk0Y2DHMpVGNTdsklFI12n2ohDP6prHk7nG0SdTBZS2NBgmlVEBnPPkN+wvL6JqaSHobfcTUEunjJqWUX4eLy9lhj4Xo0jYxzKVR4aI1CaVaIKfTMOD+LymrdHJZZjfOHtiJs6u1N8xdl+ve7pyitYiWSmsSSrUw32zcT6+7Z1NW6QTgw2U53Pj2Mq57Ywl5hWXufHd+tBqAaaf34pTeuiZ1S6VBQqkWpKTcwXVvLvV77JtNeYycMY81OUcoq6xaR+HucwfomIgWTIOEUi3IxytyvPaX3jPeJ8/5L/7A56v2AjCsW0qjlEtFLm2TUKoF2XPYWgfiXzeOxhh8ZnJ1uePfqwC4c2L/Riubikxak1CqgW3YW8DEZ7+noLTCnXa0rJJvN+2v4ayGcaCwnPTkeE7u3YFTjq+9naF967hGKJWKZFqTUCoEisoq+XTlHi46sSsJsdEA7C8o5asNudzzX2tq7aEPznXnv2BYFz5dtYdv/zCWjA6t/F4zVIrLK3njx2yuP6Unh0vKSU3y/uKfOuY43lm0gytGdicqSvjX4p3uY63j9SuipRNjIncN18zMTLNs2bJwF0OpWmVMnwXAiONSOWdQRy4f2YNhD82t5SzokpLAv28+mS4pCYh4Nw7vLyhl5hcbeXDKIJJio4mOEp88gZRXOomLsR4UPPjpOt5cmO0+NqpnOz78zUnufWMMy3YcYlCXNiTFxbD9wFHOfOpbAFbefzZtk7Q20dSIyHJjTGYorqWPm5Q6Rrvt5/wAy3cc4rHZG4MKEAB7jpRyysz5PPDpOp9j/1qyk49X7ObF+Vkcf88XPPTZ+qCu+doP2+l77xcszc6ntMLhFSAAlmzP99oXEUZmtCMpzqo19PSo2bTSmkSLp0FCqTpamp1PxvRZrNp1GICfth6s9Zw7J/ar8fjbP+3wSXt23hYAXvl+G4DPl30gj3xuBZNL//4TT87ZFNQ5gcRG61dES6efAKWC9O2m/WRMn8XVry629/MAyC0orfXcaaf1qtNrVTqcftMnP7+AG98O/Ah2wZY8r/3Xftjuk+eTW06p9fX/NLE/Z+miQgptuFYqKJUOJ796wxqEVjVSeRcx0RLw1/rvx/flqtE92HeklJjoKP5z00mUVDiY+toSn7yDu7bx2l+/t8DvNdftKWDdHv/HSsr9X7u6nmm1N5TfPLY3N9O71nyq+dOahFJBWOjnkdLuwyVeAWJsvzSv4zec1pO05HiG2APSMjPaMaRr1eC0KcO78PlvT2XioE6UV3rXHCoC1CRqcvsHK9zbx6e39jq28ZGJ7u1Eu/eVUsHQIKFULYwxXB9gKgtPGe2tX+hxdq3BX/fRtklx7on0LjyhK4O7phAbE0WFw7uX4dEya1oMVw+l6qo/jqp0OJnjMSHf+AHek/UleAQGbWdQdaGfFqVqsTT7EJVOQ4caBpY9eclQrhrdg7joKL6+4wwyM9oFzPvSVSfywbQxjO1nPfOPjRafmsRdH68BIN0eEX3feQO9jh8td3jt5xwq8dq/4dSeZM2YBMClI7rVdHtK1ajWICEi3UXkGxFZLyLrROQ2O72diHwlIlvsv1PtdBGR50UkS0RWi8iJHte61s6/RUSubbjbUip0fv/BSgDm/2FswDxn9Eujb8dkNs+YRPd2STVeLy4mitH2cqAA8TFRlHvUDEorHO5utT3sa6VXmz6joKTCa//u/1pB5eEpg8ieOZm05HhioqPInjmZJy8dVvMNKlWDYGoSlcAdxpiBwBjgFhEZCEwHvjbG9AG+tvcBJgF97D/TgL+BFVSAB4DRwCjgAVdgUSpSvPL9ViY/v4BfvVHVAOz6wm6TEMsfJvT1e96xjEyOjY7yaoNwdXkFeHnqCJ67YjjjBnj3NPpqfa7XvqvNZMrwrvUuh1L+1PrJNsbsBfba24UisgHoCkwBxtrZ3gK+Bf5kp79trKHci0SkrYh0tvN+ZYzJBxCRr4CJwHshvB+l6u38F35gze4j7v2dB4tJb2P9gp9gtyMEGlx2LI3BcdFRVFQ6OVBUxrz1uV5dapMTYt1f/OcP68Jnq/YA0NFjKdGs/UXu7RRdg1qFWJ1+/ohIBnACsBjoaAcQgH2Aq6WsK7DL47QcOy1QevXXmIZVA6FHjx51KZ5SQXM6Dc/M28yBonK27i/ilWtGeAUIgJvfXc6zlw8HYKTdxhBjN/qeN7Qzn6/e684b7HQZ/sTGRHG03EHmo/O80v94jvcAvBeuPIE/TujH6U9+Q3F5pTv9izV7Ccac20+npMJRe0alPAQdJESkNfARcLsxpsDzP4UxxohISCaBMsa8ArwC1txNobimUtVt3l/IC/Oz3PuPfL4BgImDOvHlun2ANSZh0TbrMU5CrBUc4u3eRnHRUWx42OpWmhh3bF1KYwIs6HPLmcf7pLley/PL/lCx1T7Rq5aJAvt1Sq5vEVULFlTvJhGJxQoQ7xpjPraTc+3HSNh/u+Y93g109zi9m50WKF2pRlVS7mDiswu80matsR7j3H52HxbdNc6dft8n1pxKp/e1xkCcYf/9yzHHkRgXfcwBAsBfiBg/wP9o5yT79Yo9eje52jM+ubX2kdRK1VUwvZsEeA3YYIx52uPQp4Crh9K1wCce6dfYvZzGAEfsx1JzgAkikmo3WE+w05RqNPlHyzn7me980ksrrC/ajskJdEpJ8DnuagPo2CaB7JmTGXFcCPtc+HlU1SuttZ+MVW0fnkHinUXWvE/JCdoeoUIvmMdNpwBTgTUistJOuxuYCXwoIjcAO4DL7GOzgXOBLKAYuA7AGJMvIo8ArlFJD7sasZVqLP9Zvss9puCcQR25//xBnP30d+4v3dRW1liIdq3iyD9a7j4voQFHKfurSQRqCHetNT1vfS5C4MF2SoVKML2bfsD/5xhgXPUEu1fTLQGu9Trwel0KqFQordpV1Tj98lRruv3ict/G3DevG8kFL/7YKGXy1+adVMtjrPV7CwLO76RUKOnPENViFJdXMsvuCfTK1BE+x8/0mHtpaLe2fr+8G4L4+Q1WW5Corr82SqsGokFCtRirc6xaxBMXD2XCoE7udNcAud7V2gEGd0nxOt4YxtnTc7ep43iH/wUx/bdS9aFThatm60BRGfExUSQnxLJgS557Gu2zqvUcuumM3ogI156c4ZXutJf2bejV2Vw1lmtOOo7tB44CdQsS4/qnN2ibiWrZNEioZqe80klstDD+6e+Ii47i4SmDuemfy93HO7T2ngcpJjrK75gE1/LvDR0kXMMkWsfHuNtH6jLNRyi64SoViD5uUs3Ktrwi+t77BT3vms3h4gr2F5Z5BYi6cDUM17V9oK5cA1MN8Cu7NtOzhoFx/7jGe337hi6fatm0JqGalf8sz6nxuGsth2B0SUlgz5FSnA087t81Urp3WmvOH9aFc4d0JjrAKGyAUdWmIY+P0SChGo4GCdVkHSmuYPnOfA4drWDy0M4kxEbz12+3+s17z7kDmHrScXV6dv/W9aP48xcbObl3+9ozH4NJQzrzv1tOYZi9gl1NAQKgdYL13zYxNpqSCgeHq00brlQoiTGROz1SZmamWbYs8KLvqmXLmD7La/+mM3rz9+/8B4nsmZMbo0iNamHWAa56dTH9OyXz5e2nh7s4KoKIyHJjTGbtOWunbRKqSfL348YVIM4f1oXfnN6LH/50ZmMXq1F1sBcicjT08zDVounjJtUk5RaUee27Hr0APHf5cKKifJcEbW56p7XmylHdue6UnuEuimrGNEioJmVLbiHnPr+ACof16/nhKYO4/5N17gBxw6k93fMbxcVE0alNAjeP7R228jak6CjhzxcNDXcxVDOnQUI1GcXllZz9zPdeaZeM6Ma+I6XuBuuTenk3Mi+622d6MaVUHWibhGoyPJfpdEmMjeZljzWhXbO4KqVCQ4OEahIWZh3wOyuriHDhCVWr4LbXIKFUSOnjJtUkXPXqYvf22ofOYd76XDrbiwPNvGiIexCd1iSUCi0NEiri/Zh1wGu/dXwMv/CoPcREV1WI2yToR1qpUNLHTSrivbUw2709ple7wBmpmgdJKRUa+rNLRSRjDP9elsPkoZ3d02bXNGr6vRvH6GyoSjUADRIqYlQ6nO5HRyt2HebOj1azJDufPYdLGNSlTY3nntTA8ysp1VLp4yYVEUorHPS770uenbcZgLxCa0T12t1HWLj1IOv26HrOSoWDBgkVdkVllfS/70scTsOz87aQV1jGejsobNxXGObSKdWy6eMmFXb/98FKr/13fsrm+flZXmn3Th7QiCVSSrloTUI1qoLSCh76bJ3X5Htz1+cCcHrfNMC7S6vLwM41t0kopRqGBgnVqH75j8W88WM2U1+zBsc57Wmuz+ibxtvXjwLg6a+sdonpk/qTZk+HnZwQG4bSKqU0SKhGtWb3EQAWb89n0nMLuPeTtQCM7Zfmk7ddqzh+fao1DXbHlPjGK6RSyk3bJFSjqb5Q0Ia9BWzYazVQH5/e2if/2H5ppCbFccHwLqQnJzRKGZVS3rQmoRrN2z/tCHisfyerzWH1gxPcaenJCcRGR9E5JbHBy6aU8k+DhGo0u/KLAXj1Gt+ld12zt7ZJiOWFK0/g89+e2qhlU0r5p4+bVKPJP1pOl5QEzvDT/uBaTQ6sNaqVUpFBaxKqwX2/OY9nvtrMxyt2s+dIKbHRUXz8/06mR7skAG4f3yfMJVRKBaI1CdXgrnl9iU/aiT1SiY+xfqOc2S+9sYuklAqSBgnVYIwxfPzzbq+0564Y7t5OTYrz+lspFXk0SKgG4XAaet892yd9yvCqxYKev/IE5qzbR/d22ntJqUilQUI1iI9/zqk1T6eUBK49OaPhC6OUqjdtuFYhV1Lu4Oedh9z7EwZ2BOCEHm3DVCKlVH3VWpMQkdeB84D9xpjBdtqDwI1Anp3tbmPMbPvYXcANgAP4nTFmjp0+EXgOiAZeNcbMDO2tqEjgdBoG3P8lACf3bs+/bhwDwM87D9G7g++oaqVUZAumJvEmMNFP+jPGmOH2H1eAGAhcAQyyz/mriESLSDTwEjAJGAhcaedVzUhJuYNeHu0QvdOqgsKJPVJJSdJJ+pRqamqtSRhjvheRjCCvNwV43xhTBmwXkSxglH0syxizDUBE3rfzrq97kVWkctUgXGpbclQpFfmOpU3iVhFZLSKvi0iqndYV2OWRJ8dOC5TuQ0SmicgyEVmWl5fnL4uKQAeKynzSRvZsF4aSKKVCqb5B4m9Ab2A4sBf4S6gKZIx5xRiTaYzJTEvznb5BRab5G/cDcMrx7Zk65jgAurbVrq1KNXX16gJrjMl1bYvIP4DP7d3dQHePrN3sNGpIVxFsf2EpxWUOMjq0Cpgn+8BR7vzPagDeuX40BvjDhH4kxEY3UimVUg2lXkFCRDobY/bauxcCa+3tT4F/icjTQBegD7AEEKCPiPTECg5XAFcdS8FV47jghR/ZV1BKlIDTWGtN//q0Xl55xj71LQATB3VyT9SnjdRKNQ/BdIF9DxgLdBCRHOABYKyIDAcMkA38BsAYs05EPsRqkK4EbjHGOOzr3ArMweoC+7oxZl2ob0aFXlFZJWAFCIBHZ23wChJ/mbvJvf3ohYMbtWxKqYYXTO+mK/0kv1ZD/hnADD/pswHfeRpUxNp3pNQdJAJ5YX4WAFeP6UGH1rrEqFLNjY64biEqHE4KSyuCzl9a4eCtn7L9HsuYPovSCgdvexyPidKPklLNkc7d1AL8vPMQF/11IQDb/3wuIlJjfofTkPnoPHct4vs/nkmXtglMeelH1u2x1qR+bPYGr+VI8wp9u8AqpZo+/fnXArgCBMAnK/eQMX0W8zfmBsw/Y9YGr8dMHVPiiYmO4o4Jfd1p1der3ldQGsISK6UihQaJZm75jnyv/ds/WAnAqwu2+82fV1jG6z96H4uPsbqyntkvnYenDPI6tubBCUwZ3oWHLvBOV0o1D/q4qZnbsLcQgPTkePZ7PBJyLR3qUlLuoKiskpEz5gHwxCVDuSyzu1ceEWFA56qpNv5+9QiSE2J57ooTGqr4Sqkw05pEmBw6Ws6RkuAbkuvjlnd/5t7/WUNYXrt2pNexz1bt8dof+MCX7gABkBTnfyCcZ3AZ3r1tiEqqlIpUGiTC5NTH5zPsobms2nXYK33jvgIqHM5jvv6S7fnMWrPXvd+vU7LX8aN2zcHpNNz3v7UY431+n3Tv/C4d2yS4t1vF64hqpZo7DRINbH9BKSurBYKScgdHyx0ATHnpR574ciOlFQ72Hilh4rMLGP/0dyzadrDer7nzYDGXvfyTV1pcTBS/H9+XT245hd+edTwA32zcz/7CMt5Z5N0IPaBzG5+g4umcQdYiQq3j9WmlUs2d/i9vYKMe+xqwupH2aJ/Ek3M2smDLAa88f/12K+1bx2Psn/M7DhZzxSuLyJ45uV6v+fmaqkdJUQKThnQG4LbxfQDo3i6JF+ZnMXd9Ls7qVQhgQOfAAQLghStPpKzSUWtXWqVU06dBogF9uLRqdvTTn/yGf1yTyUvfbPWbN0pg64GjXmkOpyE6qm5fxDmHinniS2uqjKwZk4iJ9q0spibF0jo+hs9W7fFpm7gssxu3je/rc46nuJgo4mK0EqpUS6BBogHd+dFqr/0b317mtb/h4YnuhXpio6NwOL1/1R8uLqd9Hae6+OWri93b/gIEWL2U/E23sfGRiTpzq1LKi/4cbCBfbwg8WM0lMS6az249FYBN+wrJ2l/kdfzg0fI6v25+kXXO/efVbXXYP56jU3srpXxpTaIBPP/1Fp7+ajMAj0wZxMGj5Tw7bwsAHdvEe3VHHdItha5tE92Nx0O7pTCkawrvLt7J9gNH6dvRt32gvNJJXlGZz6I+Hy7dRWFZJSf2aMv1p/assYye4yZevSaT8QM71v+GlVLNltYkQuxoWaU7QAAcn57M7R7P+B+7cAiDu6YwuGuKO2334RL3dlmFk7vOHQDAtjzvNgqX+/63llNmzmfBlqrlXY0x7sdb0ycNqLWcX9x2mrt3UmorXftBKeWfBokQu+7NpV77/at1Je3vMWLZ5eoxPdzbUVFCq7hoRKCk3P803a7xD1NfW4IxhkqHk+U7DrmPjwpiben2reN59vLhDO2WQv9OvmVSSinQx00h9WPWAZZst+ZK+vy3p3rVFlzS/DREP3D+IP65aCcAz1w+DBHBGHh+fhb/N6GfT37PRueT/jzfa3K939ljIIIxfmBHfcyklKqRBokQMcbwu/dWAFWPlDy9d+MY5m/M9dt1NDY6qt5jIqrPvjrlhK71uo5SSvmjQSJEPl21h4NHy2mTEMNVo3v4HD+pd3tO6t0+6OuNymjnd4yE0+k7+M0l87hUeqe1Dvo1lFKqNi26TeJISQWlFY56n785t5CM6bNYviOf+z+xlux+99djQlK22BihwuGk0uFkTc4RjDEYY7j1vZ8DnnPhiVqLUEqFVoutSXy9IZcb3lpGrw6tmP+HsfW6xhdr9gFw8d+seZImDe7EkG6+7RD1ERMVRZGjkqfmbubv31mjtKdP6s9s+zX9Wbv7SEheWymlXFpsTeKGt6zRz9sOHOWHanMpBav6gObLRnb3n7EeYqOjWJVzxB0gAGZ+sdG9/fqvMrkss5vXORntW4Xs9ZVSClpokPDsLgpw7//W1PkaG/cV8NTczV5pKYmhG29Q27XO6t+RjA5WULhgWBfenzaGX5/WK2Svr5RS0AIfNx0pruDivy30SjvxuNQ6XWP7gaNMfHaBT3p8CCe965AcF/DYE5cMBSDZHgyXnBDDmF7BN4orpVSwWlRNwhjDsIfnuveX3zsegI9/3s3GfQVBX+f291e4t1+eOgKAswd2ZKCfgXL19dnKPQGPuUZKx9tzLZVWHPsiRUop5U+zrkkcKa4gPjbKPXHdzvxi97GnLh3mNcPq8h2Hghp5XFhawaocq4H4/vMGcs6gTvUe41CTPUdKAx5bsj2fc4d0pkNrq7aR3qZuM8UqpVSwmm2Q+Nu3W3n8S6uh1/Ul/sL8LAD+cukwLh7RLeC5geQVlrnXgb74xG61TqLXUFzTeIztm86fLxrCxEGdwlIOpVTz1ywfN1U4nO4A4eJwGmat3kt6cjwX+RlPsL+gzO+1tuUVucdSPOFxzV5pjdeT6J5zvSfsc/ViiooSrhzVg9RWgdsvlFLqWDTLILHvSKl7Gu329hfowaIySiocXJbZ3e+ym7kFpRhj2Jxb6F5GdOpriznrL98x8tF5GGP49/Icd/5ppzdeT6KE2CiuHFU1ijvQYkJKKRVqzfLbpnu7JH7405lMGd6FpPhoKhxOLrJ7NJ3RL83vOdsOHOXl77cx4Znv+e+K3RwsKnOvRV1YVsmu/KrpvJfcM47YBv6i/r+zrenFB3dtw/nDujDjF4Mb9PWUUsqfZtsmISJEi7Arv4Q+93zhTs+s1t31L5cO445/r2LJ9nz3DK6bcgvZ7rHedOeUBE5/8hsAPrr5JNKTExq8/L8b14ffjevT4K+jlFI1abZBAuDjFbu99hNio3weNV08ohuv/7iddXuqusD+vOMQS7OrBtzt9ehp5G+luMZy/3kDOVJSEbbXV0q1PM3ycZPLN9XmZFp5/wS/+TwDBOAVIIZ1b+t1LDkhfKu4XX9qT35/dt/aMyqlVIg06yDRs4N3DyTXeIm6eMoe3QzWBH5KKdWSNOsgAXB5pjXp3tAaZmdd9YD/GsZJvdrTx+Px0hdrA8/AqpRSzVGzDxKPXjiY28b14Z0bRgfMk5IYy7u/to6PsBu2owTem+a9NsSAEE67oZRSTYG4xgREoszMTLNs2bJGe73DxeVs2lfI5a8sIkpg25+tkdqlFQ6e+Wozt43vQ1Jcs27rV0o1AyKy3BiTGYpr1VqTEJHXRWS/iKz1SGsnIl+JyBb771Q7XUTkeRHJEpHVInKixznX2vm3iMi1oSh8qLVNiqNraqJ72yUhNpq7zh2gAUIp1eIE87jpTWBitbTpwNfGmD7A1/Y+wCSgj/1nGvA3sIIK8AAwGhgFPOAKLJGmW2oS0yf157VrQxKElVKqSas1SBhjvgfyqyVPAd6yt98CfuGR/raxLALaikhn4BzgK2NMvjHmEPAVvoEnYtx0Rm9O6BGRMUwppRpVfRuuOxpj9trb+4CO9nZXYJdHvhw7LVC6DxGZJiLLRGRZXl5ePYunlFIqFI65d5OxWr5D1vptjHnFGJNpjMlMS/M/z5JSSqnGUd8gkWs/RsL+e7+dvhvo7pGvm50WKF0ppVQEq2+Q+BRw9VC6FvjEI/0au5fTGOCI/VhqDjBBRFLtBusJdppSSqkIVmufThF5DxgLdBCRHKxeSjOBD0XkBmAHcJmdfTZwLpAFFAPXARhj8kXkEWCpne9hY0z1xnCllFIRRgfTKaVUM9Oog+mUUkq1XBoklFJKBRTRj5tEJA+rzaO+OgAHQlScpqCl3S+0vHtuafcLLe+eQ3G/xxljQjKGIKKDxLESkWWhei7XFLS0+4WWd88t7X6h5d1zpN2vPm5SSikVkAYJpZRSATX3IPFKuAvQyFra/ULLu+eWdr/Q8u45ou63WbdJKKWUOjbNvSahlFLqGGiQUEopFZgxptH+YM0E+w2wHlgH3Gant8NaiGiL/Xeqnd4f+AkoA/5Q7VoTgU1Y80RNr+E1r7WvuwW41iN9BtYaF0W1lHkEsMZ+neexH9F5HL8Da6r0Dg18v69jzba7tpby+s0HPAlsBFYD/wXaBjjfbz7gl8BKjz9OYHhD3TOQACwBVtnXeaiGe/4SOAx8Xi39Xfszstb+d4kNcL7ffFiLaK2273cZcGoDv8fZ9mdtJbCsAd/jS+2yOoFMj/Ra3+MQvr/9qr1WAXB7I9/v2cBy+998OXBWgPND+R7fZn/O1gW63xDdc6Cypdrnrcb6/zW4pu8TY0yjB4nOwIn2djKwGRgIPIH9RY+1FOrj9nY6MBLrC93zAxYNbAV6AXFYXyQDA/xDbbP/TrW3Xf9YY+zy1BYklth5BfgCmFTtwzMHa8CfvyARkvu1j50OnFj9Q+PnNf3mw5p5N8beftz1mn7OrzUfMATY2sDvsQCt7e1YYDEwJsBrjgPOxzdInGtfR4D3gJsDnO83H9Caqna7ocDGBn6Ps/19jhrgPR6A9SX9LR5fmsG8x6G832r/n/dhDQBrtPsFTgC62NuDgd0N/JkejBUgkrAmV50HHN9A9xyobE8CD9jb/bGWoa7x89aoj5uMMXuNMT/b24XABqwV6qbgZzlUY8x+Y8xSoKLapUYBWcaYbcaYcuB9+xrVBVw21RizyFStrueXvVZGGzuvAd6maqlWgGeAOwmw6FII7xfjfxlZf6/pN58xZq4xptLeXYS1poe/84PJdyXWv7m/80Nyz8ZSZO/G2n8C/Tt/DRT6SZ9tX8dgBftA9+w3nzGmyE4DaOXv9UP5HgcrBO/xBmPMplpexu973ED3Ow4rIPmdXaGh7tcYs8IYs8feXQckiki8n3yhuucBwGJjTLFd7u+AixringOVDSu4zbevtRHIEJGOPmd7CFubhIhkYEXyxQReDjWQYJdDDXrZ1BpeJ8ff+SIyBeuXx6pgLnSM9xtq12PViuqb73KsX9w1OtZ7FpFoEVmJVe3+yhizOIgy+7tOLDAV67FUnfKJyIUishGYhfXvUdP5GRzbe2yAuSKyXESmBZG/JsG+x4HU+h6H8DN9RW2vFYRjvd+LgZ+NMWU1ZTrGe14LnCYi7UUkCasG272Wc2pS0z0HKtsq7MAkIqOA4wgcaIAwBQkRaQ18hPVMrsDzmP3Lze8vxkhhv8F3A/cHmT9i7ldE7gEqsZ7D1zmfiIwGio0xa2s5/5jv2RjjMMYMx/oQjxKRwbWdE8Bfge+NMQvqms8Y819jTH+sX2KPBDoxRO/xqcaYE4FJwC0icnoQ5/grS1DvcQ3n1/oeh+ozLSJxwAXAv+tTVvsax3q/g7Ae3fymlnzHdM/GmA3268zF+iGyEnDUs8xB33O1ss0E2to/vn4LrKitDI0eJOxfax8B7xpjPraTAy2HGojf5VBFZLSIrLT/XBAoXw1li/Y4/2E7r2eUdZ3fG+gJrBKRbDv9ZxHp1ED3G6i83T3Ke1MQ+X8FnAf80vUYRUTesM+fXVM+D7X+6gv1PRtjDmM1HE708x7XSEQeANKA//NIm2Of/2pN+aqV4Xugl4h08PMaIblfY8xu++/9WI2LoxrqPa5Fje9xiN/fSVi/4HPtcxv1fkWkG9a/9TXGmK015AvVe/yaMWaEMeZ04BCwuYHu2W/ZjDEFxpjr7B9f12B95rfVVuhG+4PVMPg28Gy19CfxbmR5otrxB/FuAIqxb6wnVQ3Xg/y8XjtgO1ajdaq93a5anro2XJ/rJ082/huuQ3K/HukZ1NJwHSgfVlvMeiCtlnMD5sP6UbEb6NUI73EaVT2rEoEFwHk1vO5YfBuufw0sBBJruWe/+YDjqWq4PtG+9+q920J1v62AZI/thcDEhniPPfJ/S7WG69re4wb4TL8PXNeQn+lA9wu0xX78Ust5IbtnIN3+uwdWL6W2DXHPgcpm33OcvX0j8Hat/27B/OOG6g9wKla1x9WtcCXWc7n2wNdY3bXmYX+RA52w2gEKsLo45mA1JGOftxmrl9M9Nbzm9VjdV7M8P4xYrf85WN3icoAHA5yfifUscSvwItW+JOw82fgPEqG83/eAvViNYTnADQHK6zefff+7PMrx9wDnB8yH9UW8qDHeY6zeRCvs66wF7q/hNRcAeUCJff45dnql/b65yuH3GoHyAX/CatBcidWl0V8X2FDdby+sLyxXl9+aPtPH+h5faJ9XBuQCc4J9j0N1v/axVsBBIKWWz1SD3C9wL3AU76646Q18zwuwvuRXAeMa8J4Dle0krO/NTcDH2L09a/qj03IopZQKSEdcK6WUCkiDhFJKqYA0SCillApIg4RSSqmANEgopZQKSIOEUh5ExGEPSlonIqtE5A4RqfH/iYhkiMhVjVVGpRqTBgmlvJUYY4YbYwZhTSU9CXiglnMyAA0SqlnScRJKeRCRImNMa4/9XsBSoAPWZGjvYA0CA7jVGLNQRBZhzfC5HWvGzeex5sgZC8QDLxljXm60m1AqhDRIKOWhepCw0w5jrUdQCDiNMaUi0gd4zxiTKSJjsaZfOM/OPw1r5O6jYk09/SNwqTFmeyPeilIhERPuAijVhMQCL4rIcKyZM/sGyDcBGCoil9j7KUAfrJqGUk2KBgmlamA/bnJgzaL5ANbcP8Ow2vNKA50G/NYYM6dRCqlUA9KGa6UCEJE04O/Ai8Z6LpsC7DXGOLEWJ4q2sxZiLWvpMge42Z5eGhHpKyKtUKoJ0pqEUt4S7QVZYrFmh30HeNo+9lfgIxG5BmvRmKN2+mrAISKrgDeB57B6PP0sIoI1Q+0vGqf4SoWWNlwrpZQKSB83KaWUCkiDhFJKqYA0SCillApIg4RSSqmANEgopZQKSIOEUkqpgDRIKKWUCuj/A0EaEZLGSdjPAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot of the stock movement\n",
    "df_sp500['Close'].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data Preparation/Data Cleaning__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null Values=\n",
      " Open         0.0\n",
      "High         0.0\n",
      "Low          0.0\n",
      "Close        0.0\n",
      "Adj Close    0.0\n",
      "Volume       0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Checking for any null values and removing the null values'''\n",
    "print('Null Values=\\n',df_sp500.isnull().sum()/len(df_sp500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2010-01-04</th>\n",
       "      <td>1116.56</td>\n",
       "      <td>1133.87</td>\n",
       "      <td>1116.56</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>1132.99</td>\n",
       "      <td>3991400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010-01-05</th>\n",
       "      <td>1132.66</td>\n",
       "      <td>1136.63</td>\n",
       "      <td>1129.66</td>\n",
       "      <td>1136.52</td>\n",
       "      <td>1136.52</td>\n",
       "      <td>2491020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Open     High      Low    Close  Adj Close      Volume\n",
       "Date                                                                 \n",
       "2010-01-04  1116.56  1133.87  1116.56  1132.99    1132.99  3991400000\n",
       "2010-01-05  1132.66  1136.63  1129.66  1136.52    1136.52  2491020000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the missing values with the last value available in the dataset. \n",
    "df_sp500=df_sp500.fillna(method='ffill')\n",
    "df_sp500.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">Evaluate Algorithms/Models</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Train Test Split__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=list(df_sp500[\"Close\"])\n",
    "X=[float(x) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_size = 0.2\n",
    "#In case the data is not dependent on the time series, then train and test split should be done based on sequential sample\n",
    "#This can be done by selecting an arbitrary split point in the ordered list of observations and creating two new datasets.\n",
    "train_size = int(len(X) * (1-validation_size))\n",
    "X_train, X_test = X[0:train_size], X[train_size:len(X)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">Implementation Steps</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Implementation Strategies & Modules:</b> The algorithm, aims to decide whether to buy, sell or hold, when provided\n",
    "with the current market price. The algorithm is based on “Q-learning based”\n",
    "approach and used Deep-Q-Network (DQN) or Deep Learning framework (Neural Network driven) to come up with a policy prescription. As discussed\n",
    "before, the name “Q-learning” comes from the Q(s, a) function, that based on the\n",
    "state s and provided action a returns the expected reward.\n",
    "\n",
    "In order to implement this DQN algorithm several functions and modules are implemented that interact with each other during the model training. \n",
    "A summary of the modules and functions is shared below.\n",
    "\n",
    "1. **Agent Class**: The agent is defined by the “Agent” class, that holds the variables and\n",
    "member functions that perform the Q-Learning. An\n",
    "object of the “Agent” class is created using the training phase and is used at the training stage of the model.\n",
    "2. **Helper functions**: In this module, we create additional functions that are helpful\n",
    "for training. There are two helper functions that we have are as follows.\n",
    "3. **Training module**: In this step, we perform the training of the data using the vari‐\n",
    "ables and the functions agent and helper methods. This will provide us with one\n",
    "of three actions (i.e. buy, sell or hold) based on the states of the stock prices at the\n",
    "end of the day. During training, the prescribed action for each day is predicted,\n",
    "the rewards are computed and the deep-learning based Q-learning model\n",
    "weights are updated iteratively over a number of episodes. Additionally, the profit\n",
    "and loss of each action is summed up to see whether an overall profit has occur‐\n",
    "red. The aim is to maximize the total profit.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b><span style=\"font-family:Comic Sans MS\">\"Agent\" module/steps</span></b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Definition of the Agent script:</b> In this step, we will train an agent that will perform reinforcement learning based on the Q-Learning. It involves following steps:\n",
    "\n",
    "* Create an agent class whose initial function takes in the batch size, state size, and an evaluation Boolean function, to check whether the training is ongoing.\n",
    "* In the agent class, create the following methods:\n",
    "    * <b>Constructor:</b> The constructor inititalises all the parameters.\n",
    "    * <b>Model:</b> This function has a deep learning model to map the state to action.\n",
    "    * <b>Act function:</b> Returns an action, given a state, using the  output of the model function. The number of actions are defined as 3: sit, buy, sell\n",
    "    * <b>expReplay:</b> Create a Replay function that adds, samples, and evaluates a buffer. Add a new experience to the replay buffer memory. Randomly sample a batch of experienced tuples from the memory. In the following function, we randomly sample states from a memory buffer. Experience replay stores a history of state, action, reward, and next state transitions that are experienced by the agent. It randomly samples mini-batches from this experience to update the network weights at each time step before the agent selects an ε-greedy action.\n",
    "\n",
    "Experience replay increases sample efficiency, reduces the autocorrelation of samples that are collected during online learning, and limits the feedback due to the current weights producing training samples that can lead to local minima or divergence.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import deque\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
    "        #State size depends and is equal to the the window size, n previous days\n",
    "        self.state_size = state_size # normalized previous days, \n",
    "        self.action_size = 3 # sit, buy, sell\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "\n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        #self.epsilon_decay = 0.9\n",
    "        \n",
    "        #self.model = self._model()\n",
    "\n",
    "        self.model = load_model(model_name) if is_eval else self._model()\n",
    "\n",
    "    #Deep Q Learning model- returns the q-value when given state as input \n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        #Input Layer\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation=\"relu\"))\n",
    "        #Hidden Layers\n",
    "        model.add(Dense(units=32, activation=\"relu\"))\n",
    "        model.add(Dense(units=8, activation=\"relu\"))\n",
    "        #Output Layer \n",
    "        model.add(Dense(self.action_size, activation=\"linear\"))\n",
    "        model.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\n",
    "        return model\n",
    "    \n",
    "    #Return the action on the value function\n",
    "    #With probability (1-$\\epsilon$) choose the action which has the highest Q-value.\n",
    "    #With probability ($\\epsilon$) choose any action at random.\n",
    "    #Intitially high epsilon-more random, later less\n",
    "    #The trained agents were evaluated by different initial random condition\n",
    "    #and an e-greedy policy with epsilon 0.05. This procedure is adopted to minimize the possibility of overfitting during evaluation.\n",
    " \n",
    "    def act(self, state): \n",
    "        #If it is test and self.epsilon is still very high, once the epsilon become low, there are no random\n",
    "        #actions suggested.\n",
    "        if not self.is_eval and random.random() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)        \n",
    "        options = self.model.predict(state)\n",
    "        #set_trace()\n",
    "        #action is based on the action that has the highest value from the q-value function.\n",
    "        return np.argmax(options[0])\n",
    "\n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        for i in range(l - batch_size + 1, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        \n",
    "        # the memory during the training phase. \n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "            target = reward # reward or Q at time t    \n",
    "            #update the Q table based on Q table equation\n",
    "            #set_trace()\n",
    "            if not done:\n",
    "                #set_trace()\n",
    "                #max of the array of the predicted. \n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])     \n",
    "                \n",
    "            # Q-value of the state currently from the table    \n",
    "            target_f = self.model.predict(state)\n",
    "            # Update the output Q table for the given action in the table     \n",
    "            target_f[0][action] = target\n",
    "            #train and fit the model where state is X and target_f is Y, where the target is updated. \n",
    "            self.model.fit(state, target_f, epochs=1, verbose=0)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Helper Functions__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following functions are getting created:\n",
    "    \n",
    "- __formatPrice:__ format the price to two decimal places, to reduce the ambiguity of the data:\n",
    "\n",
    "- __getStockData:__ Return a vector of stock data from the CSV file. Convert the closing stock prices from the data to vectors, and return a vector of all stock prices.\n",
    "\n",
    "- __getState:__ Define a function to generate states from the input vector. Create the time series by generating the states from the vectors created in the previous step. The function for this takes three parameters: the data; a time, t (the day that you want to predict); and a window (how many days to go back in time). The rate of change between these vectors will then be measured and based on the sigmoid function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# prints formatted price\n",
    "def formatPrice(n):\n",
    "    return (\"-$\" if n < 0 else \"$\") + \"{0:.2f}\".format(abs(n))\n",
    "\n",
    "# # returns the vector containing stock data from a fixed file \n",
    "# def getStockData(key):\n",
    "#     vec = []\n",
    "#     lines = open(\"data/\" + key + \".csv\", \"r\").read().splitlines()\n",
    "\n",
    "#     for line in lines[1:]:\n",
    "#         vec.append(float(line.split(\",\")[4])) #Only Close column\n",
    "\n",
    "#     return vec\n",
    "\n",
    "# returns the sigmoid\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "# returns an an n-day state representation ending at time t\n",
    "\n",
    "def getState(data, t, n):    \n",
    "    d = t - n + 1\n",
    "    block = data[d:t + 1] if d >= 0 else -d * [data[0]] + data[0:t + 1] # pad with t0\n",
    "    #block is which is the for [1283.27002, 1283.27002]\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(sigmoid(block[i + 1] - block[i]))\n",
    "    return np.array([res])\n",
    "\n",
    "# Plots the behavior of the output\n",
    "def plot_behavior(data_input, states_buy, states_sell, profit):\n",
    "    fig = plt.figure(figsize = (15,5))\n",
    "    plt.plot(data_input, color='r', lw=2.)\n",
    "    plt.plot(data_input, '^', markersize=10, color='m', label = 'Buying signal', markevery = states_buy)\n",
    "    plt.plot(data_input, 'v', markersize=10, color='k', label = 'Selling signal', markevery = states_sell)\n",
    "    plt.title('Total gains: %f'%(profit))\n",
    "    plt.legend()\n",
    "    #plt.savefig('output/'+name+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Training Phase__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will proceed to train the data, based on our agent and helper methods. This will provide us with one of three actions, based on the states of the stock prices at the end of the day. These states can be to buy, sell, or hold. During training, the prescribed action for each day is predicted, and the price (profit, loss, or unchanged) of the action is calculated. The cumulative sum will be calculated at the end of the training period, and we will see whether there has been a profit or a loss. The aim is to maximize the total profit.\n",
    "\n",
    "Steps: \n",
    "* Define the number of market days to consider as the window size and define the batch size with which the neural network will be trained.\n",
    "* Instantiate the stock agent with the window size and batch size.\n",
    "* Read the training data from the CSV file, using the helper function.\n",
    "* The episode count is defined. The agent will look at the data for so many numbers of times. An episode represents a complete pass over the data.\n",
    "* We can start to iterate through the episodes.\n",
    "* Each episode has to be started with a state based on the data and window size. The inventory of stocks is initialized before going through the data.\n",
    "* **Start to iterate over every day of the stock data. The action probability is predicted by the agent**. \n",
    "* Next, every day of trading is iterated, and the agent can act upon the data. Every day, the agent decides an action. Based on the action, the stock is held, sold, or bought.\n",
    "* If the action is 1, then agent buys the stock. \n",
    "* If the action is 2, the agent sells the stocks and removes it from the inventory. Based on the sale, the profit (or loss) is calculated.\n",
    "\n",
    "* If the action is 0, then there is no trade. The state can be called holding during that period.\n",
    "* The details of the state, next state, action etc is saved in the memory of the agent object, which is used further by the exeReply function.       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/RL_TS3.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running episode 0/10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-e7b1479b094b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mplot_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstates_buy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstates_sell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_profit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpReplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-60bb48370fc0>\u001b[0m in \u001b[0;36mexpReplay\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mtarget_f\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m#train and fit the model where state is X and target_f is Y, where the target is updated.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon_min\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1086\u001b[0m           self._maybe_load_initial_epoch_from_ckpt(initial_epoch))\n\u001b[1;32m   1087\u001b[0m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epochs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36menumerate_epochs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m     \u001b[0;34m\"\"\"Yields `(epoch, tf.data.Iterator)`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_truncate_execution_to_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m       \u001b[0mdata_iterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    703\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 705\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    706\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2969\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2970\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2971\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   2972\u001b[0m         _ctx, \"MakeIterator\", name, dataset, iterator)\n\u001b[1;32m   2973\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "window_size = 1\n",
    "agent = Agent(window_size)\n",
    "#In this step we feed the closing value of the stock price \n",
    "data = X_train\n",
    "l = len(data) - 1\n",
    "#\n",
    "batch_size = 32\n",
    "#An episode represents a complete pass over the data.\n",
    "episode_count = 10\n",
    "\n",
    "for e in range(episode_count + 1):\n",
    "    print(\"Running episode \" + str(e) + \"/\" + str(episode_count))\n",
    "    state = getState(data, 0, window_size + 1)\n",
    "    #set_trace()\n",
    "    total_profit = 0\n",
    "    agent.inventory = []\n",
    "    states_sell = []\n",
    "    states_buy = []\n",
    "    for t in range(l):\n",
    "        action = agent.act(state)    \n",
    "        # sit\n",
    "        next_state = getState(data, t + 1, window_size + 1)\n",
    "        reward = 0\n",
    "\n",
    "        if action == 1: # buy\n",
    "            agent.inventory.append(data[t])\n",
    "            states_buy.append(t)\n",
    "            #print(\"Buy: \" + formatPrice(data[t]))\n",
    "\n",
    "        elif action == 2 and len(agent.inventory) > 0: # sell\n",
    "            bought_price = agent.inventory.pop(0)      \n",
    "            reward = max(data[t] - bought_price, 0)\n",
    "            total_profit += data[t] - bought_price\n",
    "            states_sell.append(t)\n",
    "            #print(\"Sell: \" + formatPrice(data[t]) + \" | Profit: \" + formatPrice(data[t] - bought_price))\n",
    "\n",
    "        done = True if t == l - 1 else False\n",
    "        #appends the details of the state action etc in the memory, which is used further by the exeReply function\n",
    "        agent.memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"--------------------------------\")\n",
    "            print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "            print(\"--------------------------------\")\n",
    "            #set_trace()\n",
    "            #pd.DataFrame(np.array(agent.memory)).to_csv(\"Agent\"+str(e)+\".csv\")\n",
    "            #Chart to show how the model performs with the stock goin up and down for each \n",
    "            plot_behavior(data,states_buy, states_sell, total_profit)\n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)    \n",
    "            \n",
    "\n",
    "    if e % 2 == 0:\n",
    "        agent.model.save(\"model_ep\" + str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First check the model architecture\n",
    "print(agent.model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showcase the model architecture - overall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test Set performance__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training the data, it is tested it against the test dataset. Our model resulted in a overall profit. The best thing about the model was that the profits kept improving over time, indicating that it was learning well and taking better actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agent is already defined in the training set above.\n",
    "test_data = X_test\n",
    "l_test = len(test_data) - 1\n",
    "state = getState(test_data, 0, window_size + 1)\n",
    "total_profit = 0\n",
    "is_eval = True\n",
    "done = False\n",
    "states_sell_test = []\n",
    "states_buy_test = []\n",
    "#Get the trained model\n",
    "model_name = \"model_ep\"+str(episode_count)\n",
    "agent = Agent(window_size, is_eval, model_name)\n",
    "state = getState(data, 0, window_size + 1)\n",
    "total_profit = 0\n",
    "agent.inventory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(l_test):\n",
    "    action = agent.act(state)\n",
    "    #print(action)\n",
    "    #set_trace()\n",
    "    next_state = getState(test_data, t + 1, window_size + 1)\n",
    "    reward = 0\n",
    "\n",
    "    if action == 1:\n",
    "        agent.inventory.append(test_data[t])\n",
    "        states_buy_test.append(t)\n",
    "        print(\"Buy: \" + formatPrice(test_data[t]))\n",
    "\n",
    "    elif action == 2 and len(agent.inventory) > 0:\n",
    "        bought_price = agent.inventory.pop(0)\n",
    "        reward = max(test_data[t] - bought_price, 0)\n",
    "        #reward = test_data[t] - bought_price\n",
    "        total_profit += test_data[t] - bought_price\n",
    "        states_sell_test.append(t)\n",
    "        print(\"Sell: \" + formatPrice(test_data[t]) + \" | profit: \" + formatPrice(test_data[t] - bought_price))\n",
    "\n",
    "    if t == l_test - 1:\n",
    "        done = True\n",
    "    agent.memory.append((state, action, reward, next_state, done))\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        print(\"------------------------------------------\")\n",
    "        print(\"Total Profit: \" + formatPrice(total_profit))\n",
    "        print(\"------------------------------------------\")\n",
    "        \n",
    "plot_behavior(test_data,states_buy_test, states_sell_test, total_profit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__congratulations!__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
